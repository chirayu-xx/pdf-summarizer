{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chirayu-xx/pdf-summarizer/blob/main/pdf_summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjqUAY8gHvyb"
      },
      "outputs": [],
      "source": [
        "!pip install PyPDF2\n",
        "!pip install transformers\n",
        "!pip install pytesseract\n",
        "!pip install PyMuPDF\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "jszFhz3Bv5i_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/Chirayu_Shah_Resume.pdf'\n",
        "doc = fitz.open(path)\n",
        "text = \"\"\n",
        "for page_number in range(doc.page_count):\n",
        "  page = doc[page_number]\n",
        "  text += page.get_text()\n",
        "\n",
        "soup = BeautifulSoup(text, 'html.parser')\n",
        "text = soup.get_text(separator= ' ')"
      ],
      "metadata": {
        "id": "voYG2WRVuIKO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "-8-n3MsYuwbf",
        "outputId": "effb5657-a2d3-43d3-c6eb-400fe6a3acfc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Chirayu Shah\\nLocation: Chandigarh, India\\nSoftware Developer\\nPortfolio | LinkedIn | GitHub | Leetcode\\nEmail: chirayu.shah2103@gmail.com | Mobile: 9586700639\\nSUMMARY\\nDedicated software developer with adept problem-solving skills and firm grasp of system design. Proficient in Re-\\nact.js, NEXT.js, and Node.js frameworks, I excel in creating innovative solutions. A skilled team player, I contribute\\nharmoniously to collective endeavors.\\nTECHNICAL SKILLS\\nLanguages: C++, Javascript,Python,HTML,CSS\\nFrameworks: ReactJS, TailwindCSS, NEXT.JS, NodeJS,MongoDB,ExpressJS\\nCertifications: React: Design Patterns,Node JS Essential\\nOthers: Data Structures and Algorithm , System Design ,Collabaration Skills , Management Skills\\nEXPERIENCE\\nGruby Pvt Ltd, Remote: Full Stack Developer\\nDec 2022 – Jun 2023\\n• Delivered top-notch software solutions to a dynamic Saas Startup, spearheading the development and continual\\nenhancement of novel features across web portals.\\n• Orchestrated seamless team operations, facilitating effective liaison between management and the technical\\nteam, while elevating my personal tech stack, including various React.js libraries and the utilization of Tailwind\\nCSS, thereby augmenting work excellence.\\nCodbrix Lab, Remote: Frontend Developer Intern\\nAug 2022 – Aug 2022\\n• During my tenure at Codbrix Lab, I adeptly familiarized myself with the Chakra UI CSS library.\\n• Leveraged the capabilities of Chakra UI to meticulously design and develop the \"Contact Us\" page.\\nACADEMIC PROJECTS\\nEnhanced IMDb-style Website with Next.js\\nApril 2023 – April 2023\\nLed the Project Design and Development\\n• Designed and implemented an IMDb-like website using Next.js elevating UI/UX through innovative enhance-\\nments.\\n• Transformed aesthetics and interactivity, showcasing advanced Next.js features for a captivating user interface.\\nYouTube 2.0\\nWinter 2022\\nInfused familiarity with innovative enhancements\\n• Orchestrated the development of a YouTube-inspired platform, leveraging the YouTube API from Rapid APIs\\nusing React.js to replicate its functionalities while ensuring a seamless ad-free user experience.\\nACTIVITIES\\nAdobe PapyrusNebula Hackathon\\nJun 2023\\nInnovative RPA Implementation: Innovatively leveraged Adobe’s Extract API to develop an Robotic Process Au-\\ntomation (RPA) solution\\n• Enhanced Efficiency: Significantly reduced manual effort and potential errors by automating the data extraction\\nprocess, ultimately improving overall operational efficiency.\\n• API Proficiency: Mastered the intricacies of Adobe’s Extract API, harnessing its capabilities to seamlessly\\nintegrate and process document data.\\nEDUCATION\\nB.E., Computer Science with Artificial Intelligence and Machine Learning\\nGraduating June 2025\\nChandigarh University, Punjab, India\\n8.01 CGPA\\n10 + 2\\nGraduating May 2021\\nSir J J High School, Gujarat , India\\n8.61 CGPA\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FaAIHaLDjuTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "770a4fac-8da6-4c9d-d4b0-f3fbbfeec3a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dedicated software developer with adept problem-solving skills. excels in creating innovative solutions. a skilled team player, i contribute harmoniously to collective endeavors. delivered top-notch software solutions to a dynamic Saas Startup. a frontend developer at Codbrix Lab. a YouTube 2.0 winter 2022 project. a.. a.. a.. a.. a.. a.. \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "tokenizer=AutoTokenizer.from_pretrained('T5-base')\n",
        "model=AutoModelWithLMHead.from_pretrained('T5-base', return_dict=True)\n",
        "\n",
        "# Encode the text\n",
        "inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\",max_length=512, truncation=True)\n",
        "\n",
        "# Generate the summary\n",
        "outputs = model.generate(inputs,\n",
        "max_length=1000, min_length=100)\n",
        "\n",
        "# Decode the summary\n",
        "summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "OTbux4nKu6K5",
        "outputId": "66d5e1fc-c1af-4ff3-a060-44b60caf7437"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad> Dedicated software developer with adept problem-solving skills and firm grasp of system design. proficient in React.js, NEXT.js, and Node.js frameworks, excel in creating innovative solutions. delivered top-notch software solutions to a dynamic Saas Startup, spearheading the development and continual enhancement of novel features across web portals. Designed and implemented an IMDb-like website using Next.js elevating UI/UX through innovative enhance- </s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bexhuDabt7q1"
      },
      "outputs": [],
      "source": [
        "!pip install fastapi==0.103.2 nest-asyncio pyngrok uvicorn\n",
        "!pip install python-multipart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NGPy4YskUzN"
      },
      "outputs": [],
      "source": [
        "!pip install sentencepiece\n",
        "!ngrok authtoken 2ZLDE06RzMLQEbRfbRmZzhHTdSJ_5vnBBVzitpreaSLRbFGxD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "njOdkL5ekrkS"
      },
      "outputs": [],
      "source": [
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi import FastAPI, File, UploadFile,HTTPException\n",
        "from fastapi.responses import JSONResponse\n",
        "from typing import List\n",
        "import os\n",
        "import fitz  # PyMuPDF library\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        ")\n",
        "\n",
        "# Path to store uploaded files\n",
        "upload_directory = '/content/uploaded_files'\n",
        "text_directory = '/content/text_files'\n",
        "\n",
        "\n",
        "# Home route\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"message\": \"Welcome to the FastAPI server!\"}\n",
        "\n",
        "\n",
        "@app.post(\"/file\")\n",
        "async def upload_file(file: UploadFile = File(...)):\n",
        "    # Do here your stuff with the file\n",
        "    return {\"filename\": file.filename}\n",
        "\n",
        "@app.post(\"/extract-text\")\n",
        "async def extract_text_from_pdf(file: UploadFile = UploadFile(...)):\n",
        "    try:\n",
        "        # Read PDF content\n",
        "        pdf_content = await file.read()\n",
        "\n",
        "        # Open PDF with PyMuPDF\n",
        "        pdf_document = fitz.open(\"pdf\", pdf_content)\n",
        "\n",
        "        # Initialize an empty string to store extracted text\n",
        "        text = \"\"\n",
        "\n",
        "        # Iterate through pages and extract text\n",
        "        for page_number in range(pdf_document.page_count):\n",
        "            page = pdf_document[page_number]\n",
        "            text += page.get_text()\n",
        "\n",
        "        # Close the PDF document\n",
        "        pdf_document.close()\n",
        "\n",
        "        return JSONResponse(content={\"extracted_text\": text}, status_code=200)\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/summarize\")\n",
        "async def extract_text_from_pdf(file: UploadFile = UploadFile(...)):\n",
        "    try:\n",
        "        # Read PDF content\n",
        "        pdf_content = await file.read()\n",
        "\n",
        "        # Open PDF with PyMuPDF\n",
        "        pdf_document = fitz.open(\"pdf\", pdf_content)\n",
        "\n",
        "        # Initialize an empty string to store extracted text\n",
        "        text = \"\"\n",
        "\n",
        "        # Iterate through pages and extract text\n",
        "        for page_number in range(pdf_document.page_count):\n",
        "            page = pdf_document[page_number]\n",
        "            text += page.get_text()\n",
        "\n",
        "        # Initialize the model and tokenizer\n",
        "        tokenizer=AutoTokenizer.from_pretrained('T5-base')\n",
        "        model=AutoModelWithLMHead.from_pretrained('T5-base', return_dict=True)\n",
        "\n",
        "        # Encode the text\n",
        "        inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\",truncation=True)\n",
        "\n",
        "        # Generate the summary\n",
        "        outputs = model.generate(inputs,\n",
        "        max_length=1000, min_length=100)\n",
        "\n",
        "        # Decode the summary\n",
        "        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        return JSONResponse(content={\"summary\": summary}, status_code=200)\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "# Example Usage:\n",
        "# Send a PDF file to http://your-fastapi-host/extract-text using your frontend.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF-Tpyy4sE_5",
        "outputId": "3c38cf92-8031-4083-d9dc-9fa459be8d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://b6e5-34-85-172-54.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [372]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     49.249.148.147:0 - \"POST /summarize HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     49.249.148.147:0 - \"POST /summarize HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     203.145.142.86:0 - \"POST /summarize HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     203.145.142.86:0 - \"POST /summarize HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3eOhk17sLqF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz38w4+8i2jSy9/HkJydJK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}